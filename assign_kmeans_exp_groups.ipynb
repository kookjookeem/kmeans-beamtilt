{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8fcb676-b910-4218-9638-43f2b3dab6f0",
   "metadata": {},
   "source": [
    "# Assign exposure groups to particles  \n",
    "[![DOI](https://zenodo.org/badge/598765943.svg)](https://zenodo.org/badge/latestdoi/598765943)\n",
    "\n",
    "After [running `kmeans_groups.py`](https://github.com/kookjookeem/kmeans-beamtilt) for your data, assign the group IDs to your CryoSPARC particles [via `cryosparc-tools`](https://tools.cryosparc.com/intro.html).  \n",
    "See the [wiki page](https://github.com/kookjookeem/kmeans-beamtilt/wiki) on the `kmeans-beamtilt` GitHub repo for the instructions to run `kmeans_groups.py`.  \n",
    "\n",
    "For this workflow, the following dependencies are required as well as `cryosparc-tools`:  \n",
    "* `scikit-learn`  \n",
    "* `pandas`  \n",
    "* `matplotlib`  \n",
    "\n",
    "First initialize the `CryoSPARC` client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dc2e7b-4170-4671-9419-747acef853a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cryosparc.tools import CryoSPARC\n",
    "\n",
    "cs = CryoSPARC(\n",
    "    license=LICENSE,\n",
    "    host=HOSTNAME,\n",
    "    base_port=39000,\n",
    "    email=EMAIL,\n",
    "    password=PASSWORD\n",
    ")\n",
    "\n",
    "assert cs.test_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117e49d1-a94f-4518-9447-1b701ae8a2d5",
   "metadata": {},
   "source": [
    "In this example, the particles are from a Non-uniform Refinement job at `P32-J748`.   \n",
    "Locate the project and the job with `find_project` and `find_job`.  \n",
    "\n",
    "Load the `particles` as a `pandas` dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29a6d59-8f51-4898-a8ad-5d1f254acf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.float_format', None)\n",
    "\n",
    "project = cs.find_project(\"P32\")\n",
    "job = cs.find_job(\"P32\", \"J748\")\n",
    "particles = job.load_output(\"particles\")\n",
    "\n",
    "particles_df = pd.DataFrame(particles.rows()) # It might take a little time to load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5197b9e-ee50-4395-bc05-ae653c3fa8f9",
   "metadata": {},
   "source": [
    "Load the CSV file from `kmeans_groups.py` and parse the two columns to `filename` and `expgroup`.  \n",
    "Put the absolute path to `csv_file`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dada127-1133-4e54-b706-8afb719b8d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = '/Users/kookjookim/Downloads/job030_mic_class.csv'\n",
    "csv_data = pd.read_csv(csv_file, header=None, names=['filename', 'expgroup'])\n",
    "print(csv_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407a4ae0-6041-43e2-a66d-dac8c41ae331",
   "metadata": {},
   "source": [
    "Extract `location/micrograph_path` to create a column named `filename`.\n",
    "\n",
    "Set offsets for parsing:  \n",
    "`x`: Number of characters to omit counting from the START of `location/micrograph_path` (default: exclude path & UIDs)  \n",
    "`y`: Number of characters to omit counting from the END of `location/micrograph_path` (default: exclude .mrc)\n",
    "\n",
    "In this example, `J481/imported/015577085289234993444_19apr05e_00009hln_00003enn_frames_030.mrc` is parsed to `19apr05e_00009hln_00003enn` to match the `filename` in `csv_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0155e35b-b853-4087-99ec-e139821e5729",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = 0\n",
    "y = 11 # _frames_xxx\n",
    "\n",
    "# Extract from 'location/micrograph_path' to 'filename'\n",
    "particles_df['filename'] = particles_df['location/micrograph_path'].str.split('/').str[-1].str[22 + x:-4 - y]\n",
    "path_columns = particles_df.filter(items=['location/micrograph_path','filename', 'ctf/exp_group_id'])\n",
    "path_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a773c4d9-c4e0-4775-a15b-651da985512e",
   "metadata": {},
   "source": [
    "Create a dictionary to map `filename` to `expgroup` in `csv_data`.  \n",
    "Replace `ctf/exp_group_id` with `expgroup` based on `filename`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663a5b21-a798-4566-8998-cfb763611b0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_to_exp = dict(zip(csv_data['filename'], csv_data['expgroup']))\n",
    "particles_df['ctf/exp_group_id'] = particles_df['filename'].map(file_to_exp).fillna(particles_df['ctf/exp_group_id'])\n",
    "\n",
    "ctf_expgroup_columns = particles_df.filter(like='ctf/exp_group_id')\n",
    "ctf_expgroup_columns.head(60) # Showing the first 60 rows. Peep the new 'ctf/exp_group_id'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18baaf50-801a-49ca-a481-58e62c79859f",
   "metadata": {},
   "source": [
    "Create a deep copy of the `particles` dataset and replace `ctf/exp_group_id` with the one in `particles_df` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e0880e-1dc7-4bc5-a149-d68335cdc674",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_particles = particles.copy()\n",
    "updated_particles[\"ctf/exp_group_id\"] = particles_df[\"ctf/exp_group_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8461327b-843a-4245-bb7e-f1f91aff2979",
   "metadata": {},
   "source": [
    "Save the particles with the new `ctf/exp_group_id` assignment.  \n",
    "Create an external job with the updated particles as the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98407ba-e817-4ba5-b7e6-0b9bd85809a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.save_external_result(\n",
    "    workspace_uid=\"W13\",\n",
    "    dataset=updated_particles,\n",
    "    type=\"particle\",\n",
    "    name=\"km_beamtilt_particles\",\n",
    "    slots=[\"ctf\"],\n",
    "    passthrough=(job.uid, \"particles\"),\n",
    "    title=\"Beamtilt grouped particles\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284ac1a1-3e8e-4116-9a60-7102b5920d66",
   "metadata": {},
   "source": [
    "You can now run Homogeneous Refinement, Non-uniform Refinement, or Global CTF Refinement to optimize per-group (global) CTF params."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
